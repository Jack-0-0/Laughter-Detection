{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tgt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(filepath, start, stop, y, sr):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        filepath: wav audio filepath.\n",
    "        start: start time in seconds.\n",
    "        stop: stop time in seconds.\n",
    "        y: audio time series.\n",
    "        sr: sample rate.\n",
    "        \n",
    "    # Outputs\n",
    "        saves a numpy file of the mel spectrogram array with\n",
    "        dimensions (n_mels, t)\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(y=y[sr * start:(sr * stop)],\n",
    "                                       sr=sr, n_mels=64, fmax=sr / 2) \n",
    "    path_save = os.path.dirname(filepath) + '/' + os.path.basename(filepath).split('.')[0]\n",
    "    np.save(path_save + '_' + str(start) + 'to' + str(stop) + '_spectro', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(audio_path)\n",
    "            for name in files\n",
    "            if name.endswith((\".wav\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "slide = 3\n",
    "for filepath in wavs:\n",
    "    y, sr = librosa.load(filepath)\n",
    "    length = int(len(y) / sr)\n",
    "    remainder = length % window_size\n",
    "    for i in tqdm(range(0, length-remainder, window_size), desc='save_spectro', leave=False):\n",
    "            save_spectrogram(filepath, i, i + window_size, y, sr)\n",
    "            j = i + slide\n",
    "            if j + window_size < length-remainder:\n",
    "                save_spectrogram(filepath, j, j + window_size, y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TextGrid file to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_csv(file, annotation_path):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        file: TextGrid filepath.\n",
    "        annotation_path: directory of annotations.\n",
    "        \n",
    "    # Outputs\n",
    "        saves a filtered TextGrid file that contains only tiers that contain\n",
    "        'laugh' as csv file.\n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_laugh_list = [tier for tier in tier_list if 'laugh' not in tier]\n",
    "    for tier in tier_no_laugh_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Laugh.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_part_csv(file, annotation_path):  \n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        file: TextGrid filepath.\n",
    "        annotation_path: directory of annotations.\n",
    "        \n",
    "    # Outputs\n",
    "        saves a filtered TextGrid file that contains only tiers that contain\n",
    "        'Part' as csv file. To be used to determine when roleplay\n",
    "        starts.\n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_part_list = [tier for tier in tier_list if 'Part' not in tier]\n",
    "    for tier in tier_no_part_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Parts.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = 'transcriptions_annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TextGrid_files = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(annotation_path)\n",
    "             for name in files\n",
    "             if name.endswith((\".TextGrid\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(TextGrid_files, desc='tg to csv'):\n",
    "    convert_tg_file_to_csv(file, annotation_path)\n",
    "    convert_tg_file_to_part_csv(file, annotation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset (combine: id, spectrogram, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_start_end(spectro_file, annotation_path):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        spectro_file: spectrogram filepath.\n",
    "        annotation_path: directory of annotations.\n",
    "        \n",
    "    # Returns\n",
    "        label_path: label filepath relating to the spectrogram.\n",
    "        start_time: start time relating to the spectrogram.\n",
    "        end_time: end time relating to the spectrogram.\n",
    "        roleplay_path: roleplay parts information filepath relating to the spectrogram.\n",
    "    \"\"\"\n",
    "    base_file = os.path.basename(spectro_file)\n",
    "    start_time = int(base_file.split('_')[1].split('to')[0])\n",
    "    end_time = int(base_file.split('_')[1].split('to')[1])\n",
    "    \n",
    "    label_dir = annotation_path + os.path.dirname(spectro_file).split('/')[-1]\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith((\"Laugh.txt\"))]\n",
    "    label_path = label_dir + '/' + label_files[0]\n",
    "    \n",
    "    roleplay_files = [f for f in os.listdir(label_dir) if f.endswith((\"Parts.txt\"))] \n",
    "    roleplay_path = label_dir + '/' + roleplay_files[0]\n",
    "    return label_path, start_time, end_time, roleplay_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_csv(start_time, end_time, label_path):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        start_time: start time relating to spectrogram.\n",
    "        end_time: end time relating to spectrogram.\n",
    "        label_path: filepath of label.\n",
    "        \n",
    "    # Returns\n",
    "        dataframe filtered to contain 'laugh' in the text\n",
    "        and filtered for specified start_time and end_time.\n",
    "        When start_time in the csv is before specified start_time,\n",
    "        this record will be included but start_time in the csv will be set\n",
    "        to specified start_time. Same for end_time.\n",
    "        \n",
    "        For example:\n",
    "    \n",
    "        start_time    end_time     text\n",
    "        905.765658    909.731864   <laughter> jaha läuft </laughter>\n",
    "    \n",
    "        if start_time was 907 and end_time was 909, filter_csv would set this row to:\n",
    "    \n",
    "        start_time    end_time     text\n",
    "        907.0         909.0        <laughter> jaha läuft </laughter>\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(label_path)\n",
    "    df = df[df['text'].str.contains('laugh') == True]\n",
    "    df = df[df['start_time'] <= end_time]\n",
    "    df = df[df['end_time'] >= start_time]\n",
    "    df.loc[df.end_time > end_time, 'end_time'] = end_time\n",
    "    df.loc[df.start_time < start_time, 'start_time'] = start_time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(spectro_file):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        spectro_file: filepath for spectrogram.\n",
    "        \n",
    "    # Returns\n",
    "        id for file.\n",
    "        For example input of spectro_file of 'audio/r7/r7_270to276_spectro.npy'\n",
    "        would return 'r7_270to276'.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(spectro_file)\n",
    "    r = base_name.split('_')[0]\n",
    "    times = base_name.split('_')[1]\n",
    "    file_id = r + '_' + times\n",
    "    return file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_in_timesteps(df, start_time, timesteps_per_second):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        df: dataframe in format from output of function filter_csv.\n",
    "        start_time: start time relating to spectrogram.\n",
    "        timesteps_per_second: timesteps_per_second = timesteps / window_size.\n",
    "        \n",
    "    # Returns\n",
    "        dataframe after:\n",
    "        Removing tier_name, tier_type and text columns.\n",
    "        Reformating times to start from 0 and end at 6.\n",
    "        Converting seconds to timesteps.\n",
    "    \"\"\"\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    df['start_time'] = df['start_time'] - start_time\n",
    "    df['start_time'] = (df['start_time'] * timesteps_per_second).apply(np.floor)\n",
    "    df['end_time'] = df['end_time'] - start_time\n",
    "    df['end_time'] = (df['end_time'] * timesteps_per_second).apply(np.ceil)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_matrix(df):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        df: dataframe in format from output of start_end_in_timesteps.\n",
    "        \n",
    "    # Returns\n",
    "        vector of length (timesteps) which has values of 0 or 1.\n",
    "        1 representing laughter, 0 representing no laughter.\n",
    "    \n",
    "        For example:\n",
    "        [1, 0, 0, 1, 0, 0 ....] represents laughter in timesteps 0 and 3\n",
    "    \"\"\"\n",
    "    label = np.zeros(timesteps)\n",
    "    update_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        update_list.append([row['start_time'], row['end_time']])\n",
    "    for l in update_list:\n",
    "        start = int(l[0])\n",
    "        end = int(l[1])\n",
    "        label[start:end] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_spectro_label(file_id, spectro_path, label):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        file_id: file id created from function create_id.\n",
    "        spectro_path: filepath for spectrogram.\n",
    "        label: label created from function create_label_matrix.\n",
    "        \n",
    "    # Returns\n",
    "        numpy array containing 3 elements:\n",
    "        id\n",
    "        related spectrogram\n",
    "        related label\n",
    "    \"\"\"\n",
    "    np_spectro_file = np.load(spectro_path)\n",
    "    combined = [file_id, np_spectro_file, label]\n",
    "    np_combined = np.asarray(combined)\n",
    "    return np_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roleplay_flag(roleplay_path):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        roleplay_path: filepath for Parts file which has times for annotated roleplays.\n",
    "        \n",
    "    # Returns\n",
    "        True if the start and end times of the spectrogram\n",
    "        are during the annotated roleplay times. Else returns False.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(roleplay_path)\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    roleplay_times = []\n",
    "    for index, row in df.iterrows():\n",
    "        roleplay_times.append([row['start_time'], row['end_time']])\n",
    "    proceed_flag = False\n",
    "    for rp in roleplay_times:\n",
    "        if start_time <= rp[1] and end_time >= rp[0]:\n",
    "            proceed_flag = True\n",
    "    return proceed_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectros = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(audio_path)\n",
    "            for name in files\n",
    "            if name.endswith((\"spectro.npy\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "window_size = 6\n",
    "timesteps = 259 \n",
    "timesteps_per_second = timesteps / window_size\n",
    "\n",
    "for spectro_path in tqdm(spectros, desc='create dataset'):\n",
    "    label_path, start_time, end_time, roleplay_path = find_label_start_end(spectro_path, annotation_path)\n",
    "    if roleplay_flag(roleplay_path):\n",
    "        df = filter_csv(start_time, end_time, label_path)\n",
    "        df = start_end_in_timesteps(df, start_time, timesteps_per_second)\n",
    "        df_label = create_label_matrix(df)\n",
    "        file_id = create_id(spectro_path)\n",
    "        np_combined = create_id_spectro_label(file_id, spectro_path, df_label)\n",
    "        dataset.append(np_combined)\n",
    "dataset = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Validation, Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = dataset.shape[0]\n",
    "train_size = round(dataset_size * 0.75)\n",
    "val_size =  round(dataset_size * 0.15)\n",
    "test_size = round(dataset_size * 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:, 1]\n",
    "y = dataset[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat x to (n, timesteps, mel bands, 1)\n",
    "x = np.expand_dims(np.moveaxis(np.stack(x), 1, -1), axis=3)\n",
    "# reformat y to (n, timesteps, 1)\n",
    "y = np.expand_dims(np.moveaxis(np.stack(y), 1, -1), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[0:train_size]\n",
    "y_train = y[0:train_size]\n",
    "x_val = x[train_size:train_size + val_size]\n",
    "y_val = y[train_size:train_size + val_size]\n",
    "x_test = x[train_size + val_size:dataset_size]\n",
    "y_test = y[train_size + val_size:dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('de_laughter_ds', dataset)\n",
    "np.save('x_train', x_train)\n",
    "np.save('x_val', x_val)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_val', y_val)\n",
    "np.save('y_test', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
