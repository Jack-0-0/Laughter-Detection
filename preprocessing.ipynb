{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tgt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(filepath, start, stop, y, sr):\n",
    "    \"\"\"\n",
    "    Input: .wav filepath, with start and stop time in seconds,\n",
    "            y audio time series, sr samples rate of audio time\n",
    "            series\n",
    "    Output: Save a numpy file of mel spectrogram array of \n",
    "            dimension (n_mels, t)\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(y=y[sr * start:(sr * stop)],\n",
    "                                       sr=sr, n_mels=64, fmax=sr / 2) \n",
    "    path_save = os.path.dirname(filepath) + '/' + os.path.basename(filepath).split('.')[0]\n",
    "    np.save(path_save + '_' + str(start) + 'to' + str(stop) + '_spectro', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(audio_path)\n",
    "            for name in files\n",
    "            if name.endswith((\".wav\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "slide = 3\n",
    "for filepath in wavs:\n",
    "    y, sr = librosa.load(filepath)\n",
    "    length = int(len(y) / sr)\n",
    "    remainder = length % window_size\n",
    "    for i in ange(0, length-remainder, window_size):\n",
    "            save_spectrogram(filepath, i, i + window_size, y, sr)\n",
    "            j = i + slide\n",
    "            if j + window_size < length-remainder:\n",
    "                save_spectrogram(filepath, j, j + window_size, y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TextGrid file to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_csv(file, annotation_path):\n",
    "    \"\"\"\n",
    "    Filters TextGrid file to leave only tiers that are\n",
    "    named containing 'laugh'\n",
    "    Outputs a csv file\n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_laugh_list = [tier for tier in tier_list if 'laugh' not in tier]\n",
    "    for tier in tier_no_laugh_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Laugh.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_part_csv(file, annotation_path):\n",
    "    \"\"\"\n",
    "    Filters TextGrid file to leave only tiers that are\n",
    "    named containing 'Part'. To be used to determine when roleplay\n",
    "    starts.\n",
    "    Outputs a csv file\n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_part_list = [tier for tier in tier_list if 'Part' not in tier]\n",
    "    for tier in tier_no_part_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Parts.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = 'transcriptions_annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TextGrid_files = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(annotation_path)\n",
    "             for name in files\n",
    "             if name.endswith((\".TextGrid\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(TextGrid_files, desc='tg to csv'):\n",
    "    convert_tg_file_to_csv(file, annotation_path)\n",
    "    convert_tg_file_to_part_csv(file, annotation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset (combine: id, spectrogram, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_start_end(spectro_file, annotation_path):\n",
    "    \"\"\"\n",
    "    From spectrogram file, find and return:\n",
    "    label path\n",
    "    start time\n",
    "    end time\n",
    "    roleplay path\n",
    "    \"\"\"\n",
    "    base_file = os.path.basename(spectro_file)\n",
    "    start_time = int(base_file.split('_')[1].split('to')[0])\n",
    "    end_time = int(base_file.split('_')[1].split('to')[1])\n",
    "    \n",
    "    label_dir = annotation_path + os.path.dirname(spectro_file).split('/')[-1]\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith((\"Laugh.txt\"))]\n",
    "    label_path = label_dir + '/' + label_files[0]\n",
    "    \n",
    "    roleplay_files = [f for f in os.listdir(label_dir) if f.endswith((\"Parts.txt\"))] \n",
    "    roleplay_path = label_dir + '/' + roleplay_files[0]\n",
    "    return label_path, start_time, end_time, roleplay_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_csv(start_time, end_time, label_path):\n",
    "    \"\"\"\n",
    "    Output a dataframe.\n",
    "    Dataframe is filtered to contain 'laugh' in the text\n",
    "    and contains records for specified start_time and end_time.\n",
    "    When start_time in the csv is before specified start_time,\n",
    "    this record will be included but start_time in the csv will be set\n",
    "    to specified start_time. Same for end_time.\n",
    "    For example:\n",
    "    \n",
    "    start_time\tend_time\ttext\n",
    "    905.765658\t909.731864\t<laughter> jaha läuft </laughter>\n",
    "    \n",
    "    if start_time was 907 and end_time was 909, this row would be set to:\n",
    "    \n",
    "    start_time\tend_time\ttext\n",
    "    907.0\t909.0\t<laughter> jaha läuft </laughter>\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(label_path)\n",
    "    df = df[df['text'].str.contains('laugh')==True]\n",
    "    df = df[df['start_time'] <= end_time]\n",
    "    df = df[df['end_time'] >= start_time]\n",
    "    df.loc[df.end_time > end_time, 'end_time'] = end_time\n",
    "    df.loc[df.start_time < start_time, 'start_time'] = start_time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(spectro_file):\n",
    "    \"\"\"\n",
    "    Return id for file\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(spectro_file)\n",
    "    r = base_name.split('_')[0]\n",
    "    times = base_name.split('_')[1]\n",
    "    file_id = r + '_' + times\n",
    "    return file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_in_timesteps(df, start_time, timesteps_per_second):\n",
    "    \"\"\"\n",
    "    Return dataframe after:\n",
    "    Removing tier_name, tier_type and text columns\n",
    "    Reformating times to start from 0 and end at 6\n",
    "    Converting seconds to timesteps\n",
    "    \"\"\"\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    df['start_time'] = df['start_time'] - start_time\n",
    "    df['start_time'] = (df['start_time'] * timesteps_per_second).apply(np.floor)\n",
    "    df['end_time'] = df['end_time'] - start_time\n",
    "    df['end_time'] = (df['end_time'] * timesteps_per_second).apply(np.ceil)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_matrix(df):\n",
    "    \"\"\"\n",
    "    Output vector of length (timesteps) with accompanying id\n",
    "    Vector has values of 0 or 1\n",
    "    1 representing laughter, 0 representing no laughter.\n",
    "    \n",
    "    For example:\n",
    "    [1, 0, 0, 1, 0, 0 ....] represents laughter in timesteps 0 and 3\n",
    "    \"\"\"\n",
    "    label = np.zeros(timesteps)\n",
    "    update_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        update_list.append([row['start_time'], row['end_time']])\n",
    "    for l in update_list:\n",
    "        start = int(l[0])\n",
    "        end = int(l[1])\n",
    "        label[start:end] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_spectro_label(file_id, spectro_path, label):\n",
    "    \"\"\"\n",
    "    Output a matrix containing 3 elements:\n",
    "    id in format r, start_time, end_time\n",
    "    related spectrogram\n",
    "    related label\n",
    "    \"\"\"\n",
    "    np_spectro_file = np.load(spectro_path)\n",
    "    combined = [file_id, np_spectro_file, label]\n",
    "    np_combined = np.asarray(combined)\n",
    "    return np_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roleplay_flag(roleplay_path):\n",
    "    \"\"\"\n",
    "    Checks that the start and end times of the spectrogram\n",
    "    are during the annotated roleplay times of the annotation file\n",
    "    Return True if during annotated roleplay, else False.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(roleplay_path)\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    roleplay_times = []\n",
    "    for index, row in df.iterrows():\n",
    "        roleplay_times.append([row['start_time'], row['end_time']])\n",
    "    proceed_flag = False\n",
    "    for rp in roleplay_times:\n",
    "        if start_time <= rp[1] and end_time >= rp[0]:\n",
    "            proceed_flag = True\n",
    "    return proceed_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectros = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(audio_path)\n",
    "            for name in files\n",
    "            if name.endswith((\"spectro.npy\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "window_size = 6\n",
    "timesteps = 259 \n",
    "timesteps_per_second = timesteps / window_size\n",
    "\n",
    "for spectro_path in spectros:\n",
    "    label_path, start_time, end_time, roleplay_path = find_label_start_end(spectro_path, annotation_path)\n",
    "    if roleplay_flag(roleplay_path):\n",
    "        df = filter_csv(start_time, end_time, label_path)\n",
    "        df = start_end_in_timesteps(df, start_time, timesteps_per_second)\n",
    "        df_label = create_label_matrix(df)\n",
    "        file_id = create_id(spectro_path)\n",
    "        np_combined = create_id_spectro_label(file_id, spectro_path, df_label)\n",
    "        dataset.append(np_combined)\n",
    "dataset = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('de_laughter_ds',dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
