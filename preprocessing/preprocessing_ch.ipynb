{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tgt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "audio_path = '/laughter/DUEL/ch/audio'\n",
    "annotation_path = '/laughter/DUEL/ch/transcriptions_annotations/'\n",
    "save_path = '/laughter/DUEL/datasets/ch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(filepath, save_path, start, stop, y, sr):\n",
    "    \"\"\"Convert audio to spectrogram and save.\n",
    "    \n",
    "    # Arguments\n",
    "        filepath: wav audio filepath.\n",
    "        start: start time in seconds.\n",
    "        stop: stop time in seconds.\n",
    "        y: audio time series.\n",
    "        sr: sample rate.\n",
    "        \n",
    "    # Outputs\n",
    "        saves a numpy file of the mel spectrogram array with\n",
    "        dimensions (n_mels, t)\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(y=y[sr * start:(sr * stop)],\n",
    "                                       sr=sr, n_mels=64, fmax=sr/2)\n",
    "    rp = os.path.basename(filepath).split('.')[0].split('_')[0]\n",
    "    rpid = os.path.basename(filepath).split('.')[0]\n",
    "    if not os.path.isdir(save_path + '/' + rp):\n",
    "        os.makedirs(save_path + '/' + rp)\n",
    "    save_path = save_path + '/' + rp + '/' + rpid + '_' + str(start) + 'to' + str(stop) + '_spectro'\n",
    "    np.save(save_path, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3s = [os.path.join(root, name)\n",
    "        for root, dirs, files in os.walk(audio_path)\n",
    "        for name in files\n",
    "        if name.endswith((\".mp3\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "slide = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in tqdm(mp3s, desc='load audio'):\n",
    "    y, sr = librosa.load(filepath, mono=True)\n",
    "    length = int(len(y) / sr)\n",
    "    remainder = length % window_size\n",
    "    for i in tqdm(range(0, length - remainder - window_size, slide), desc='save_spectro', leave=False):\n",
    "        save_spectrogram(filepath, save_path, i, i + window_size, y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TextGrid file to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_csv(file, annotation_path):\n",
    "    \"\"\"Filter TextGrid file for laughter and convert to csv.\n",
    "    \n",
    "    # Arguments\n",
    "    file: TextGrid file.\n",
    "    annotation_path: folder containing annotations.\n",
    "    \n",
    "    # Saves\n",
    "    csv file which is a filtered TextGrid file with only \n",
    "    tiers that are named containing 'laugh'\n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_laugh_list = [tier for tier in tier_list if 'laugh' not in tier]\n",
    "    for tier in tier_no_laugh_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Laugh.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextGrid_files = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(annotation_path)\n",
    "             for name in files\n",
    "             if name.endswith((\".TextGrid\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(TextGrid_files, desc='tg to csv'):\n",
    "    convert_tg_file_to_csv(file, annotation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset (combine: id, spectrogram, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_start_end(spectro_file, annotation_path):\n",
    "    \"\"\"Find the label path, start and end time relating to spectrogram.\n",
    "    \n",
    "    # Arguments\n",
    "        spectro_file: spectrogram filepath.\n",
    "        annotation_path: directory of annotations.\n",
    "        \n",
    "    # Returns\n",
    "        label_path: label filepath relating to the spectrogram.\n",
    "        start_time: start time relating to the spectrogram.\n",
    "        end_time: end time relating to the spectrogram.\n",
    "    \"\"\"\n",
    "    base_file = os.path.basename(spectro_file)\n",
    "    \n",
    "    start_time = int(base_file.split('_')[2].split('to')[0])\n",
    "    end_time = int(base_file.split('_')[2].split('to')[1])\n",
    "    \n",
    "    rx = base_file.split('_')[0] + '_' + base_file.split('_')[1]\n",
    "    \n",
    "    label_dir = annotation_path + os.path.dirname(spectro_file).split('/')[-1]\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith((rx + \"_Laugh.txt\"))]\n",
    "    label_path = label_dir + '/' + label_files[0]\n",
    "    \n",
    "    return label_path, start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_csv(start_time, end_time, label_path):\n",
    "    \"\"\"Filters csv file for start and end time, returns as dataframe.\n",
    "    \n",
    "    # Arguments\n",
    "        start_time: start time relating to spectrogram.\n",
    "        end_time: end time relating to spectrogram.\n",
    "        label_path: filepath of label.\n",
    "        \n",
    "    # Returns\n",
    "        dataframe filtered to contain 'laugh' in the text\n",
    "        and filtered for specified start_time and end_time.\n",
    "        When start_time in the csv is before specified start_time,\n",
    "        this record will be included but start_time in the csv will be set\n",
    "        to specified start_time. Same for end_time.\n",
    "        \n",
    "    # Example\n",
    "        start_time    end_time     text\n",
    "        905.765658    909.731864   L\n",
    "\n",
    "        if start_time was 907 and end_time was 909, this row would be set to:\n",
    "\n",
    "        start_time    end_time     text\n",
    "        907.0         909.0        L\n",
    "    \"\"\"    \n",
    "    df = pd.read_csv(label_path)\n",
    "    df = df[df['text'].str.contains('sigh') == False] # Remove sighs\n",
    "    df = df[df['text'].str.contains('nonspeech') == False] # Remove nonspeech\n",
    "    df = df[df['start_time'] <= end_time]\n",
    "    df = df[df['end_time'] >= start_time]\n",
    "    df.loc[df.end_time > end_time, 'end_time'] = end_time\n",
    "    df.loc[df.start_time < start_time, 'start_time'] = start_time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(spectro_file):\n",
    "    \"\"\"Create identifier for spectrogram.\n",
    "    \n",
    "    # Arguments\n",
    "        spectro_file: filepath for spectrogram.\n",
    "        \n",
    "    # Returns\n",
    "        id for file.\n",
    "        \n",
    "    # Example\n",
    "        input of spectro_file of 'audio/r7/r7_270to276_spectro.npy'\n",
    "        would return 'r7_270to276'.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(spectro_file)\n",
    "    r = base_name.split('_')[0]\n",
    "    r2 = base_name.split('_')[1]\n",
    "    times = base_name.split('_')[2]\n",
    "    file_id = r + '_' + r2 + '_' + times\n",
    "    return file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_in_timesteps(df, start_time, timesteps_per_second):\n",
    "    \"\"\"Convert start and end time from seconds to timesteps.\n",
    "    Remove tier_name, tier_type and text columns.\n",
    "    Reformat times to start from 0 and end at window_size.\n",
    "    \n",
    "    # Arguments\n",
    "        df: dataframe in format from output of function filter_csv.\n",
    "        start_time: start time relating to spectrogram.\n",
    "        timesteps_per_second: timesteps_per_second = timesteps / window_size.\n",
    "        \n",
    "    # Returns\n",
    "        dataframe after modifications.\n",
    "    \"\"\"\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    df['start_time'] = df['start_time'] - start_time\n",
    "    df['start_time'] = (df['start_time'] * timesteps_per_second).apply(np.floor)\n",
    "    df['end_time'] = df['end_time'] - start_time\n",
    "    df['end_time'] = (df['end_time'] * timesteps_per_second).apply(np.ceil)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_matrix(df):\n",
    "    \"\"\"Convert label annotations into a matrix.\n",
    "    \n",
    "    # Arguments\n",
    "        df: dataframe in format from output of start_end_in_timesteps.\n",
    "        \n",
    "    # Returns\n",
    "        vector of length (timesteps) which has values of 0 or 1.\n",
    "        1 representing laughter, 0 representing no laughter.\n",
    "    \n",
    "    # Example\n",
    "        [1, 0, 0, 1, 0, 0 ....] represents laughter in timesteps 0 and 3\n",
    "    \"\"\"\n",
    "    label = np.zeros(timesteps)\n",
    "    update_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        update_list.append([row['start_time'], row['end_time']])\n",
    "    for l in update_list:\n",
    "        start = int(l[0])\n",
    "        end = int(l[1])\n",
    "        label[start:end] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_spectro_label(file_id, spectro_path, label):\n",
    "    \"\"\"Combine id, spectrogram and label.\n",
    "    \n",
    "    # Arguments\n",
    "        file_id: file id created from function create_id.\n",
    "        spectro_path: filepath for spectrogram.\n",
    "        label: label created from function create_label_matrix.\n",
    "        \n",
    "    # Returns\n",
    "        numpy array containing 3 elements:\n",
    "        id\n",
    "        related spectrogram\n",
    "        related label\n",
    "    \"\"\"\n",
    "    np_spectro_file = np.load(spectro_path)\n",
    "    combined = [file_id, np_spectro_file, label]\n",
    "    np_combined = np.asarray(combined)\n",
    "    return np_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roleplay_flag(label_path):\n",
    "    \"\"\"States whether label path is during the roleplay or not.\n",
    "    Roleplay start is when first annotation for the audio fiel is made.\n",
    "    \n",
    "    # Arguments\n",
    "        label_path: filepath for Laugh file.\n",
    "        \n",
    "    # Returns\n",
    "        True if the start and end times of the spectrogram\n",
    "        are during the annotated roleplay times. Else returns False.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(label_path)\n",
    "    df = df.sort_values(by=['start_time'])\n",
    "    roleplay_start = int(df.head(1)['start_time']) - np.random.randint(low=1, high=7)\n",
    "    proceed_flag = False\n",
    "    if start_time >= roleplay_start:\n",
    "            proceed_flag = True\n",
    "    return proceed_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectros = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(save_path)\n",
    "            for name in files\n",
    "            if name.endswith((\"spectro.npy\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "spectro_eg = np.load(spectros[0])\n",
    "timesteps = spectro_eg.shape[1] \n",
    "timesteps_per_second = timesteps / window_size\n",
    "\n",
    "for spectro_path in tqdm(spectros, desc='create dataset'):\n",
    "    label_path, start_time, end_time = find_label_start_end(spectro_path, annotation_path)\n",
    "    if roleplay_flag(label_path):\n",
    "        df = filter_csv(start_time, end_time, label_path)\n",
    "        df = start_end_in_timesteps(df, start_time, timesteps_per_second)\n",
    "        df_label = create_label_matrix(df)\n",
    "        file_id = create_id(spectro_path)\n",
    "        np_combined = create_id_spectro_label(file_id, spectro_path, df_label)\n",
    "        dataset.append(np_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check laughter rate and save train, val and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_laugh_rate(dataset, percentage_laughs):\n",
    "    \"\"\"Increase the laughter rate in the dataset.\n",
    "    \n",
    "    # Arguments\n",
    "        dataset: dataset to have laughter percentage increased.\n",
    "        percentage_laughs: desired percentage for dataset of \n",
    "                           examples containing a laugh. As integer.\n",
    "    \n",
    "    # Reurns\n",
    "        dataset_inc_laughs: dataset with increased rate of \n",
    "                            examples containing a laugh.\n",
    "    \"\"\"\n",
    "    laugh = [example for example in dataset if 1 in example[2]]\n",
    "    laugh_count = len(laugh)\n",
    "    no_laugh = [example for example in dataset if 1 not in example[2]]\n",
    "    no_laugh_count = len(no_laugh)\n",
    "    \n",
    "    delete_from_no_laugh = len(dataset) - laugh_count * 100 / percentage_laughs\n",
    "    delete_from_no_laugh = int(delete_from_no_laugh)\n",
    "    \n",
    "    no_laugh = no_laugh[0:-delete_from_no_laugh]\n",
    "    \n",
    "    dataset_inc_laughs = np.vstack((laugh, no_laugh))\n",
    "    return dataset_inc_laughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laughter_check(dataset):\n",
    "    \"\"\"Check the percentage of clips that contain laughter in the dataset.\n",
    "    \n",
    "    # Arguments\n",
    "        dataset: dataset to be checked.\n",
    "    \n",
    "    # Returns\n",
    "        percentage of examples containing laughter.\n",
    "    \"\"\"\n",
    "    laughs = len([e for e in dataset[:, 2] if 1 in e])\n",
    "    total = len(dataset[:, 2])\n",
    "    laughter_p = laughs / total\n",
    "    return laughter_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3047, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21234000656383328"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laughter_check(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = [e for e in dataset \n",
    "             if 'r6' not in e[0]\n",
    "             and 'r2' not in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [e for e in dataset \n",
    "        if 'r6' in e[0]\n",
    "        or 'r2' in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2141552511415525\n",
      "0.19407894736842105\n",
      "0.21518987341772153\n"
     ]
    }
   ],
   "source": [
    "train_val = np.asarray(train_val)\n",
    "np.random.shuffle(train_val)\n",
    "val_split = int(len(dataset) * 0.1)\n",
    "train = train_val[:-val_split]\n",
    "val = train_val[-val_split:]\n",
    "\n",
    "test = np.asarray(test)\n",
    "np.random.shuffle(test)\n",
    "print(laughter_check(train))\n",
    "print(laughter_check(val))\n",
    "print(laughter_check(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1422, 3)\n",
      "0.329817158931083\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(laughter_check(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1422, 3)\n",
      "0.329817158931083\n"
     ]
    }
   ],
   "source": [
    "train = increase_laugh_rate(train, 33)\n",
    "print(train.shape)\n",
    "print(laughter_check(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304, 3)\n",
      "0.19407894736842105\n"
     ]
    }
   ],
   "source": [
    "print(val.shape)\n",
    "print(laughter_check(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(553, 3)\n",
      "0.21518987341772153\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(laughter_check(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path+'ch_train_6_6_64_ds', train)\n",
    "np.save(save_path+'ch_val_6_6_64_ds', val)\n",
    "np.save(save_path+'ch_test_6_6_64_ds', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
