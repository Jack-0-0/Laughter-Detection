{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tgt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "audio_path = '/laughter/DUEL/de/audio'\n",
    "annotation_path = '/laughter/DUEL/de/transcriptions_annotations/'\n",
    "save_path = '/laughter/DUEL/datasets/de/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectrograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(filepath, save_path, start, stop, y, sr):\n",
    "    \"\"\"Convert audio to spectrogram and save.\n",
    "    \n",
    "    # Arguments\n",
    "        filepath: wav audio filepath.\n",
    "        start: start time in seconds.\n",
    "        stop: stop time in seconds.\n",
    "        y: audio time series.\n",
    "        sr: sample rate.\n",
    "        \n",
    "    # Outputs\n",
    "        saves a numpy file of the mel spectrogram array with\n",
    "        dimensions (n_mels, t)\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(y=y[sr * start:(sr * stop)],\n",
    "                                       sr=sr, n_mels=64, fmax=sr / 2)\n",
    "    rp = os.path.basename(filepath).split('.')[0]\n",
    "    if not os.path.isdir(save_path + '/' + rp):\n",
    "        os.makedirs(save_path + '/' + rp)\n",
    "    save_path = save_path + '/' + rp + '/' + rp + '_' + str(start) + 'to' + str(stop) + '_spectro'\n",
    "    np.save(save_path, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(audio_path)\n",
    "            for name in files\n",
    "            if name.endswith((\".wav\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "slide = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in tqdm(wavs, desc='load audio'):\n",
    "    y, sr = librosa.load(filepath, mono=True)\n",
    "    length = int(len(y) / sr)\n",
    "    remainder = length % window_size\n",
    "    for i in tqdm(range(0, length - remainder - window_size, slide), desc='save_spectro', leave=False):\n",
    "        save_spectrogram(filepath, save_path, i, i + window_size, y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TextGrid file to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_csv(file, annotation_path):\n",
    "    \"\"\"Filter TextGrid annotation file for laughter and convert to csv.\n",
    "    \n",
    "    # Arguments\n",
    "        file: TextGrid file.\n",
    "        annotation_path: folder containing annotations.\n",
    "    \n",
    "    # Saves\n",
    "        csv file which is a filtered TextGrid file with only \n",
    "        tiers that are named containing 'laugh'.\n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_laugh_list = [tier for tier in tier_list if 'laugh' not in tier]\n",
    "    for tier in tier_no_laugh_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Laugh.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tg_file_to_part_csv(file, annotation_path):\n",
    "    \"\"\"Filter TextGrid annotation file for parts and convert to csv.\n",
    "    To be used to determine when roleplay starts, this is needed\n",
    "    as there is audio outside of the roleplay, which has not been\n",
    "    annotated.\n",
    "    \n",
    "    # Arguments\n",
    "        file: TextGrid file.\n",
    "        annotation_path: folder containing annotations.\n",
    "    \n",
    "    # Saves\n",
    "        csv file which is a filtered TextGrid file with only \n",
    "        tiers that are named containing 'part'. \n",
    "    \"\"\"\n",
    "    tg = tgt.io.read_textgrid(file, include_empty_intervals=True)\n",
    "    tier_list = tg.get_tier_names()\n",
    "    tier_no_part_list = [tier for tier in tier_list if 'Part' not in tier]\n",
    "    for tier in tier_no_part_list:\n",
    "        tg.delete_tier(tier)\n",
    "    csv = tgt.io.export_to_table(tg, separator=',')\n",
    "    save_name = os.path.basename(file).split('.')[0] + '_Parts.txt'\n",
    "    save_dir = os.path.dirname(file)\n",
    "    save_file = save_dir + '/' + save_name\n",
    "    with open(save_file, 'w') as output:\n",
    "        output.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextGrid_files = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(annotation_path)\n",
    "             for name in files\n",
    "             if name.endswith((\".TextGrid\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(TextGrid_files, desc='tg to csv'):\n",
    "    convert_tg_file_to_csv(file, annotation_path)\n",
    "    convert_tg_file_to_part_csv(file, annotation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset (combine: id, spectrogram, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_start_end(spectro_file, annotation_path):\n",
    "    \"\"\"Find the label path, start and end time relating to spectrogram.\n",
    "    \n",
    "    # Arguments\n",
    "        spectro_file: spectrogram filepath.\n",
    "        annotation_path: directory of annotations.\n",
    "        \n",
    "    # Returns\n",
    "        label_path: label filepath relating to the spectrogram.\n",
    "        start_time: start time relating to the spectrogram.\n",
    "        end_time: end time relating to the spectrogram.\n",
    "        roleplay_path: roleplay parts information filepath relating to the spectrogram.\n",
    "    \"\"\"\n",
    "    base_file = os.path.basename(spectro_file)\n",
    "    start_time = int(base_file.split('_')[1].split('to')[0])\n",
    "    end_time = int(base_file.split('_')[1].split('to')[1])\n",
    "    \n",
    "    label_dir = annotation_path + os.path.dirname(spectro_file).split('/')[-1]\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith((\"Laugh.txt\"))]\n",
    "    label_path = label_dir + '/' + label_files[0]\n",
    "    \n",
    "    roleplay_files = [f for f in os.listdir(label_dir) if f.endswith((\"Parts.txt\"))] \n",
    "    roleplay_path = label_dir + '/' + roleplay_files[0]\n",
    "    return label_path, start_time, end_time, roleplay_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_csv(start_time, end_time, label_path):\n",
    "    \"\"\"Filters csv file for start and end time, returns as dataframe.\n",
    "    \n",
    "    # Arguments\n",
    "        start_time: start time relating to spectrogram.\n",
    "        end_time: end time relating to spectrogram.\n",
    "        label_path: filepath of label.\n",
    "        \n",
    "    # Returns\n",
    "        dataframe filtered to contain 'laugh' in the text\n",
    "        and filtered for specified start_time and end_time.\n",
    "        When start_time in the csv is before specified start_time,\n",
    "        this record will be included but start_time in the csv will be set\n",
    "        to specified start_time. Same for end_time.\n",
    "        \n",
    "        For example:\n",
    "    \n",
    "        start_time    end_time     text\n",
    "        905.765658    909.731864   <laughter> jaha läuft </laughter>\n",
    "    \n",
    "        if start_time was 907 and end_time was 909, filter_csv would set this row to:\n",
    "    \n",
    "        start_time    end_time     text\n",
    "        907.0         909.0        <laughter> jaha läuft </laughter>\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(label_path)\n",
    "    df = df[df['text'].str.contains('laugh') == True]\n",
    "    df = df[df['text'].str.contains('Offset') == False] # Remove offsets\n",
    "    df = df[df['start_time'] <= end_time]\n",
    "    df = df[df['end_time'] >= start_time]\n",
    "    df.loc[df.end_time > end_time, 'end_time'] = end_time\n",
    "    df.loc[df.start_time < start_time, 'start_time'] = start_time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(spectro_file):\n",
    "    \"\"\"Create identifier for spectrogram.\n",
    "    \n",
    "    # Arguments\n",
    "        spectro_file: filepath for spectrogram.\n",
    "        \n",
    "    # Returns\n",
    "        id for file.\n",
    "        \n",
    "    # Example\n",
    "        input of spectro_file of 'audio/r7/r7_270to276_spectro.npy'\n",
    "        would return 'r7_270to276'.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(spectro_file)\n",
    "    r = base_name.split('_')[0]\n",
    "    times = base_name.split('_')[1]\n",
    "    file_id = r + '_' + times\n",
    "    return file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_in_timesteps(df, start_time, timesteps_per_second):\n",
    "    \"\"\"Convert start and end time from seconds to timesteps.\n",
    "    Reformating times to start from 0 and end at 6.\n",
    "    Removing tier_name, tier_type and text columns.\n",
    "    \n",
    "    # Arguments\n",
    "        df: dataframe in format from output of function filter_csv.\n",
    "        start_time: start time relating to spectrogram.\n",
    "        timesteps_per_second: timesteps_per_second = timesteps / window_size.\n",
    "        \n",
    "    # Returns\n",
    "        dataframe after modifications.\n",
    "    \"\"\"\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    df['start_time'] = df['start_time'] - start_time\n",
    "    df['start_time'] = (df['start_time'] * timesteps_per_second).apply(np.floor)\n",
    "    df['end_time'] = df['end_time'] - start_time\n",
    "    df['end_time'] = (df['end_time'] * timesteps_per_second).apply(np.ceil)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_matrix(df):\n",
    "    \"\"\"Convert label annotations into a matrix.\n",
    "    \n",
    "    # Arguments\n",
    "        df: dataframe in format from output of start_end_in_timesteps.\n",
    "        \n",
    "    # Returns\n",
    "        vector of length (timesteps) which has values of 0 or 1.\n",
    "        1 representing laughter, 0 representing no laughter.\n",
    "    \n",
    "    # Example:\n",
    "        [1, 0, 0, 1, 0, 0 ....] represents laughter in timesteps 0 and 3\n",
    "    \"\"\"\n",
    "    label = np.zeros(timesteps)\n",
    "    update_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        update_list.append([row['start_time'], row['end_time']])\n",
    "    for l in update_list:\n",
    "        start = int(l[0])\n",
    "        end = int(l[1])\n",
    "        label[start:end] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_spectro_label(file_id, spectro_path, label):\n",
    "    \"\"\"Combine id, spectrogram and label.\n",
    "    \n",
    "    # Arguments\n",
    "        file_id: file id created from function create_id.\n",
    "        spectro_path: filepath for spectrogram.\n",
    "        label: label created from function create_label_matrix.\n",
    "        \n",
    "    # Returns\n",
    "        numpy array containing 3 elements:\n",
    "        id\n",
    "        related spectrogram\n",
    "        related label\n",
    "    \"\"\"\n",
    "    np_spectro_file = np.load(spectro_path)\n",
    "    combined = [file_id, np_spectro_file, label]\n",
    "    np_combined = np.asarray(combined)\n",
    "    return np_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roleplay_flag(roleplay_path):\n",
    "    \"\"\"States whether label path is during the roleplay or not.\n",
    "    This is decided by the 'Parts.txt' file which has roleplay start\n",
    "    and end times.\n",
    "    \n",
    "    # Arguments\n",
    "        roleplay_path: filepath for Parts file which has times for annotated roleplays.\n",
    "        \n",
    "    # Returns\n",
    "        True if the start and end times of the spectrogram\n",
    "        are during the annotated roleplay times. Else returns False.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(roleplay_path)\n",
    "    df = df.drop(['tier_name', 'tier_type', 'text'], 1)\n",
    "    roleplay_times = []\n",
    "    for index, row in df.iterrows():\n",
    "        roleplay_times.append([row['start_time'], row['end_time']])\n",
    "    proceed_flag = False\n",
    "    for rp in roleplay_times:\n",
    "        if start_time <= rp[1] and end_time >= rp[0]:\n",
    "            proceed_flag = True\n",
    "    return proceed_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectros = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(save_path)\n",
    "            for name in files\n",
    "            if name.endswith((\"spectro.npy\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "spectro_eg = np.load(spectros[0])\n",
    "timesteps = spectro_eg.shape[1] \n",
    "timesteps_per_second = timesteps / window_size\n",
    "\n",
    "for spectro_path in tqdm(spectros, desc='create dataset'):\n",
    "    label_path, start_time, end_time, roleplay_path = find_label_start_end(spectro_path, annotation_path)\n",
    "    if roleplay_flag(roleplay_path):\n",
    "        df = filter_csv(start_time, end_time, label_path)\n",
    "        df = start_end_in_timesteps(df, start_time, timesteps_per_second)\n",
    "        df_label = create_label_matrix(df)\n",
    "        file_id = create_id(spectro_path)\n",
    "        np_combined = create_id_spectro_label(file_id, spectro_path, df_label)\n",
    "        dataset.append(np_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save train, val and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = [e for e in dataset \n",
    "             if 'r17' not in e[0]\n",
    "             and 'r18' not in e[0]\n",
    "             and 'r19' not in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [e for e in dataset \n",
    "        if 'r17' in e[0]\n",
    "        or 'r18' in e[0]\n",
    "        or 'r19' in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = np.asarray(train_val)\n",
    "np.random.shuffle(train_val)\n",
    "val_split = int(len(dataset) * 0.1)\n",
    "train = train_val[:-val_split]\n",
    "val = train_val[-val_split:]\n",
    "\n",
    "test = np.asarray(test)\n",
    "np.random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path + 'de_train_6_6_64_ds', train)\n",
    "np.save(save_path + 'de_val_6_6_64_ds', val)\n",
    "np.save(save_path + 'de_test_6_6_64_ds', test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
